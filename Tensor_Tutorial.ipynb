{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensor_Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Deep Learning with PyTorch**\n",
        "\n",
        "PyTorch is a Python-based computing package. It is serving two broad purposes.\n",
        "\n",
        "1. A replacement for NumPy (NP) to use the power of graphic processing units (GPUs) and other acceloerators.\n",
        "2. An automatic differentiation library that is useful to implement neural networks (NN).\n",
        "\n",
        "Goal of this notebook.\n",
        "\n",
        "- Understand PyTorchâ€™ Tensor library and NNs at high-level.\n",
        "- Train a small NN to classify images.\n",
        "\n",
        "**Note**\n",
        "\n",
        "Install Torch and TorchVision packages."
      ],
      "metadata": {
        "id": "2MXEXYPEQWcF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vzEmS0wGQRwS"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensors**\n",
        "\n",
        "Tensors are known as a specialized data structure that are closely similar to arrays and matrices.\n",
        "\n",
        "In PyTorch computing package, we use tensors to encode the I/Ps and O/Ps of a model, as well as the model's parameters.\n",
        "\n",
        "Tensors are similar to NP's ndarrays (N-dimensional arrays), except that tensors can run on GPUs to accelerate computation.\n",
        "\n",
        "**ndarray:** An ndarry is a multidimensional container of items of the same type and size."
      ],
      "metadata": {
        "id": "fKzqROW6Q22t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "FBWyHcpPQtnB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensor Initialization**\n",
        "\n",
        "It can initiate in several ways.\n",
        "\n",
        "Example\n",
        "\n",
        "**Directly from Data:** It can be created directly from data and the data type is automatically inferred."
      ],
      "metadata": {
        "id": "94DuvcjyTrs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [[2,3], [4,5]]\n",
        "x_data = torch.tensor(data)"
      ],
      "metadata": {
        "id": "CyucSjCNQ0qe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From a NumPy array:** It can be created from NumPy array."
      ],
      "metadata": {
        "id": "adnj_hOLUy8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)"
      ],
      "metadata": {
        "id": "KAmYyCa4Uctv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From another tensor:** The new tensor retains the properties (datatype, shape) of the augment tesnor, unless explicity overridden."
      ],
      "metadata": {
        "id": "DfekATExVAeD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_ones = torch.ones_like(x_data) # Retains the properties of x_data\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) # Overrides the datatype of x_data\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgySDmXlUpS1",
        "outputId": "6f80c040-5e90-4bb0-cd7e-0ab9b00882cc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.9147, 0.9657],\n",
            "        [0.2390, 0.9336]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**With Random or Constant Values:** Shape is a tuple of tensor dimensions. In the function belwo, it determins the dimensionality of the O/P tensor."
      ],
      "metadata": {
        "id": "whqhnnQ6XftU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shape = (4,5,)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qok3jU1NVwFY",
        "outputId": "f252d80e-3c79-4590-bffa-e0721d799cbf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.5127, 0.1700, 0.8246, 0.7209, 0.1559],\n",
            "        [0.1611, 0.6174, 0.9436, 0.7843, 0.9657],\n",
            "        [0.3057, 0.8423, 0.6854, 0.8967, 0.9992],\n",
            "        [0.6004, 0.0155, 0.4525, 0.6010, 0.5830]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensor Attributes:** Tensor attributes describe their datatype, shape, and the device on which they are stored."
      ],
      "metadata": {
        "id": "OUZgcsVWYjVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand(4,5)\n",
        "print(f\"Datatype of Tensor: {tensor.dtype}\")\n",
        "print(f\"Shape of Tensor: {tensor.shape}\")\n",
        "print(f\"Devie tensor is stored on: {tensor.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f95GtBEDYeV3",
        "outputId": "6148fe24-0c1c-4c09-e1ce-febeaba5f0e7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datatype of Tensor: torch.float32\n",
            "Shape of Tensor: torch.Size([4, 5])\n",
            "Devie tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensor Operations:** Over 100 tensor operations, including transposing, indexing, slicing, mathematical operations, linear algebra, random sampling, and more are comprehensively described on PyTorch webpag."
      ],
      "metadata": {
        "id": "XVTNaHHCZgRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#! one can move tensor to GPU if availabe\n",
        "if torch.cuda.is_available():\n",
        "  tensor = tensor.to('cuda')\n",
        "  print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzRfYmWvaqoT",
        "outputId": "4b3435e8-3e61-4579-8948-bcc0224a6609"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device tensor is stored on: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Standard NumPy-Like Indexing and Slicing**"
      ],
      "metadata": {
        "id": "r4lQpOvUbQ_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.ones(5,5)\n",
        "tensor[:,2] = 0\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkGlrfF5a_Kf",
        "outputId": "34ec0587-35a8-4c1e-b41b-1bd407f1df06"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 0., 1., 1.],\n",
            "        [1., 1., 0., 1., 1.],\n",
            "        [1., 1., 0., 1., 1.],\n",
            "        [1., 1., 0., 1., 1.],\n",
            "        [1., 1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multiplying Tensors**"
      ],
      "metadata": {
        "id": "pk-w8K_wb3bL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#! This computes the element-wise product\n",
        "print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n",
        "\n",
        "#! Alternative syntax:\n",
        "print(f\"tensor * tensor \\n {tensor * tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgP5fmb2bkSc",
        "outputId": "e2d8429a-8665-4b65-a4aa-49732861fd00"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor.mul(tensor) \n",
            " tensor([[1., 1., 0., 1., 1.],\n",
            "        [1., 1., 0., 1., 1.],\n",
            "        [1., 1., 0., 1., 1.],\n",
            "        [1., 1., 0., 1., 1.],\n",
            "        [1., 1., 0., 1., 1.]]) \n",
            "\n",
            "tensor * tensor \n",
            " tensor([[1., 1., 0., 1., 1.],\n",
            "        [1., 1., 0., 1., 1.],\n",
            "        [1., 1., 0., 1., 1.],\n",
            "        [1., 1., 0., 1., 1.],\n",
            "        [1., 1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Matrix Multiplication Between Two Tensors**"
      ],
      "metadata": {
        "id": "omx0N9cocbnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#! This computes the matrix multiplication between two tensors\n",
        "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
        "\n",
        "#! Aternative syntax:\n",
        "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8H5Qr9ePcVBj",
        "outputId": "5ad83833-4442-4142-dd10-881af924f34b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor.matmul(tensor.T) \n",
            " tensor([[4., 4., 4., 4., 4.],\n",
            "        [4., 4., 4., 4., 4.],\n",
            "        [4., 4., 4., 4., 4.],\n",
            "        [4., 4., 4., 4., 4.],\n",
            "        [4., 4., 4., 4., 4.]]) \n",
            "\n",
            "tensor @ tensor.T \n",
            " tensor([[4., 4., 4., 4., 4.],\n",
            "        [4., 4., 4., 4., 4.],\n",
            "        [4., 4., 4., 4., 4.],\n",
            "        [4., 4., 4., 4., 4.],\n",
            "        [4., 4., 4., 4., 4.]])\n"
          ]
        }
      ]
    }
  ]
}